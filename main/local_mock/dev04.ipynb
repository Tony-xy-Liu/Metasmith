{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enable lineage constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from metasmith.models.solver import Endpoint, Namespace, _set_default_namespace\n",
    "from metasmith.models.libraries import *\n",
    "\n",
    "from local.utils import LinkifyPath\n",
    "from local.constants import WORKSPACE_ROOT\n",
    "CACHE = WORKSPACE_ROOT/\"main/local_mock/cache\"\n",
    "\n",
    "_set_default_namespace(Namespace(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = DataTypeLibrary.Load(WORKSPACE_ROOT/\"main/local_mock/prototypes/metagenomics.dev3.yml\")\n",
    "xgdb = DataInstanceLibrary.Load(CACHE/\"test.xgdb\")\n",
    "refdb = DataInstanceLibrary.Load(CACHE/\"ref.xgdb\")\n",
    "len(types), len(xgdb), len(refdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond.py <class 'metasmith.models.libraries.TransformInstance'>\n",
      "pprodigal.py <class 'metasmith.models.libraries.TransformInstance'>\n"
     ]
    }
   ],
   "source": [
    "trlib = TransformInstanceLibrary.Load([\n",
    "    Path(\"./transforms/simple_1\"),\n",
    "    # Path(\"./transforms/dupe_test\"),\n",
    "])\n",
    "for k, v in trlib:\n",
    "    print(k.name, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ref.xgdb/pprodigal.oci.uri', '/home/tony/workspace/tools/Metasmith/main/local_mock/cache/test.xgdb/example.fna']->['orfs.faa']\n",
      "./../../main/local_mock/transforms/simple_1/pprodigal.py\n",
      "['/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ref.xgdb/diamond.oci.uri', 'orfs.faa', '/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ref.xgdb/uniprot_sprot.dmnd']->['annotations.csv']\n",
      "./../../main/local_mock/transforms/simple_1/diamond.py\n"
     ]
    }
   ],
   "source": [
    "from metasmith.models.workflow import WorkflowPlan\n",
    "\n",
    "plan = WorkflowPlan.Generate(\n",
    "    given=[xgdb, refdb],\n",
    "    transforms=trlib,\n",
    "    targets=[\n",
    "        types[\"orf_annotations\"].WithLineage([\n",
    "            types[\"contigs\"],\n",
    "            # xgdb[\"example.fna\"].type,\n",
    "        ]),\n",
    "    ],\n",
    ")\n",
    "\n",
    "for step in plan.steps:\n",
    "    print([f\"{x.source}\" for x in step.uses], [f\"{x.source}\" for x in step.produces], sep=\"->\")\n",
    "    LinkifyPath(step.transform._source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metasmith.models.workflow import Workspace\n",
    "\n",
    "# base = Workspace(source=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS = Path(\"./cache/ws1/run_dev4\")\n",
    "BOOTSTRAP_BASH = WS/\"bootstrap.sh\"\n",
    "os.system(f\"rm -r {WS}\")\n",
    "WS.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache/ws1/run_dev4/bootstrap.sh\n"
     ]
    }
   ],
   "source": [
    "from metasmith.agents.bootstrap import Container\n",
    "\n",
    "CONTAINER = Container(\n",
    "    image = \"quay.io/hallamlab/metasmith:0.3\",\n",
    "    binds = [\n",
    "        (WORKSPACE_ROOT/\"main/relay_agent/dist\", \"/app\"),\n",
    "        (WORKSPACE_ROOT/\"src/metasmith\", \"/opt/conda/envs/metasmith_env/lib/python3.12/site-packages/metasmith\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "_deployment = Path(\"./.msm\")\n",
    "_relay_path = _deployment/\"relay\"\n",
    "cmd_deploy = CONTAINER.RunCommand(\"metasmith api deploy_from_container\")\n",
    "cmd_start_relay = f\"nohup {_relay_path}/server --io {_relay_path}/connections start >{_deployment}/logs/relay.log 2>&1 &\"\n",
    "cmd_start_task = CONTAINER.RunCommand('metasmith api execute_transform --body \"{\\\\\"context\\\\\": \\\\\"$1\\\\\"}\"')\n",
    "cmd_stop_relay = f\"{_relay_path}/server --io {_relay_path}/connections stop\"\n",
    "with open(BOOTSTRAP_BASH, \"w\") as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(cmd_deploy + \"\\n\")\n",
    "    f.write(cmd_start_relay + \"\\n\")\n",
    "    f.write(cmd_start_task + \"\\n\")\n",
    "    f.write(cmd_stop_relay + \"\\n\")\n",
    "\n",
    "LinkifyPath(BOOTSTRAP_BASH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache/ws1/run_dev4/workflow.nf\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from metasmith.models.libraries import ExecutionContext\n",
    "\n",
    "TAB = \" \"*4\n",
    "wf_path = WS/\"workflow.nf\"\n",
    "context_dir = WS/\"contexts\"\n",
    "context_dir.mkdir(parents=True, exist_ok=True)\n",
    "contexts: dict[str, Path] = {}\n",
    "process_definitions = {}\n",
    "workflow_definition = []\n",
    "target_endpoints = {x for x in plan.targets}\n",
    "used_libraries = {lib for step in plan.steps for lib in step.transform._used_libraries}\n",
    "for step in plan.steps:\n",
    "    name = f\"{step.transform._source.stem}__{step.transform_key}\"\n",
    "    if name not in process_definitions:\n",
    "        src = [f\"process {name}\"+\" {\"]\n",
    "        to_pubish = [x for x in step.produces if x in target_endpoints]\n",
    "        for x in to_pubish:\n",
    "            src.append(TAB+f'publishDir \"$params.output\", mode: \"copy\", pattern: \"{x.source}\"')\n",
    "        if len(to_pubish)>0:\n",
    "            src.append(\"\") # newline\n",
    "\n",
    "        src += [\n",
    "            TAB+\"input:\",\n",
    "            TAB+TAB+f'path bootstrap',\n",
    "            TAB+TAB+f'path context',\n",
    "        ] + [\n",
    "            TAB+TAB+f'path _{i+1:02} // {str(x.type).replace(\":\"+x.type.key, \"\")}' for i, x in enumerate(step.uses)\n",
    "        ] + [\n",
    "            \"\",\n",
    "            TAB+\"output:\",\n",
    "        ] + [\n",
    "            TAB+TAB+f'path \"{x.source}\"' for x in step.produces\n",
    "        ] + [\n",
    "            \"\",\n",
    "            TAB+'script:',\n",
    "            TAB+'\"\"\"',\n",
    "        ] + [\n",
    "            TAB+f'bash $bootstrap $context',\n",
    "            TAB+'\"\"\"',\n",
    "            \"}\"\n",
    "        ]\n",
    "        process_definitions[name] = \"\\n\".join(src)\n",
    "\n",
    "    step_key = f\"{step.order:03}\"\n",
    "    context_path = context_dir/f\"{step_key}.yml\"\n",
    "    context = ExecutionContext(\n",
    "        input = [x for x in step.uses],\n",
    "        output = [x for x in step.produces],\n",
    "        transform_definition = step.transform._source,\n",
    "        type_libraries = used_libraries,\n",
    "    )\n",
    "    with open(context_path, \"w\") as f:\n",
    "        yaml.dump(context.Pack(), f)\n",
    "    contexts[step_key] = context_path\n",
    "\n",
    "    output_vars = [f\"_{x.type.key}\" for x in step.produces]\n",
    "    output_vars = ', '.join(output_vars)\n",
    "    if len(step.produces) > 1:\n",
    "        output_vars = f\"({output_vars})\"\n",
    "    input_vars = ['bootstrap', f'context_{step_key}']+[f\"_{x.type.key}\" for x in step.uses]\n",
    "    input_vars = ', '.join(input_vars)\n",
    "    workflow_definition.append(TAB+f'{output_vars} = {name}({input_vars})')\n",
    "\n",
    "workflow_definition = [\n",
    "    \"workflow {\",\n",
    "    TAB+f'bootstrap = Channel.fromPath(\"{BOOTSTRAP_BASH.resolve()}\")',\n",
    "] + [\n",
    "    TAB+f'context_{k} = Channel.fromPath(\"{p.resolve()}\")' for k, p in contexts.items()\n",
    "] + [\n",
    "    \"\",\n",
    "] + [\n",
    "    TAB+f'_{x.type.key}'+f' = Channel.fromPath(\"{x.source.resolve()}\") // {x.type}' for x in plan.given\n",
    "] + [\n",
    "    \"\",\n",
    "] + workflow_definition + [\n",
    "    \"}\",\n",
    "]\n",
    "\n",
    "wf_contents = [\n",
    "    \"\\n\\n\".join(process_definitions.values()),\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\".join(workflow_definition),\n",
    "    \"\\n\",\n",
    "]\n",
    "wf_contents = ''.join(wf_contents)\n",
    "with open(wf_path, \"w\") as f:\n",
    "    f.write(wf_contents)\n",
    "\n",
    "LinkifyPath(wf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: \u001b[33mNextflow 24.10.4 is available - Please consider updating your version to it\u001b[m\n",
      "I: \u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 24.10.2\u001b[m\n",
      "I: \u001b[K\n",
      "I: WARN: It appears you have never run this project before -- Option `-resume` is ignored\n",
      "I: Launching\u001b[35m `/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/run_dev4/workflow.nf` \u001b[0;2m[\u001b[0;1;36mjovial_swartz\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m519e30a6da\u001b[m\n",
      "I: \u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[3;2mPlus \u001b[1m1\u001b[0;3;2m more processes waiting for tasks…\u001b[m\u001b[K\n",
      "I: \u001b[3A\n",
      "I: \u001b[2mexecutor >  slurm (1)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[3;2mPlus \u001b[1m1\u001b[0;3;2m more processes waiting for tasks…\u001b[m\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (1)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[3;2mPlus \u001b[1m1\u001b[0;3;2m more processes waiting for tasks…\u001b[m\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (1)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mdiamo\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (2)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34mab/7df910\u001b[0;2m] \u001b[0;2m\u001b[mdiamo\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (2)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34mab/7df910\u001b[0;2m] \u001b[0;2m\u001b[mdiamo\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (2)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34mab/7df910\u001b[0;2m] \u001b[0;2m\u001b[mdiamo\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[4A\n",
      "I: \u001b[2mexecutor >  slurm (2)\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34m09/865251\u001b[0;2m] \u001b[0;2m\u001b[mpprod\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "I: \u001b[2m[\u001b[0;34mab/7df910\u001b[0;2m] \u001b[0;2m\u001b[mdiamo\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "from metasmith.coms.ipc import LiveShell\n",
    "\n",
    "with LiveShell() as shell:\n",
    "    shell.Exec(\n",
    "        f\"\"\"\\\n",
    "        PATH={WORKSPACE_ROOT/\"main/local_mock/mock\"}:$PATH\n",
    "        cd {WS.resolve()}\n",
    "        nextflow -C ../../../config/nxf_slurm.nf \\\n",
    "            -log {(WS/\"logs\").resolve()}/log \\\n",
    "            run {wf_path.resolve()} \\\n",
    "            -resume \\\n",
    "            -work-dir {(WS/\"work\").resolve()} \\\n",
    "            --account dummy_slurm_account\n",
    "        \"\"\",\n",
    "        timeout=None,\n",
    "        silent=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
