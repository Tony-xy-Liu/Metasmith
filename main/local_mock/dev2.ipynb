{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert plan to nextflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from metasmith.solver import WorkflowSolver\n",
    "from metasmith.models.libraries import DataInstanceLibrary, DataTypeLibrary, TransformInstanceLibrary\n",
    "\n",
    "from local.constants import WORKSPACE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = DataTypeLibrary.Load(WORKSPACE_ROOT/\"main/local_mock/prototypes/metagenomics.yml\")\n",
    "trlib = TransformInstanceLibrary.Load([\n",
    "    Path(\"./transforms/simple_1\"),\n",
    "    # Path(\"./transforms/dupe_test\"),\n",
    "])\n",
    "ilib_path = Path(\"./cache/test.yml\")\n",
    "ilib = DataInstanceLibrary.Load(ilib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = WorkflowSolver(trlib)\n",
    "plan = solver.Solve(\n",
    "    [\n",
    "        ilib[\"contigs\"],\n",
    "        ilib[\"diamond_reference.uniprot_sprot\"],\n",
    "    ],\n",
    "    [\n",
    "        lib.types[\"orf_annotations\"],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process pprodigal__VMBv {\n",
      "    container \"docker://quay.io/hallamlab/external_pprodigal:1.0.1\"\n",
      "\n",
      "    input:\n",
      "        path _AlhL\n",
      "\n",
      "    output:\n",
      "        path \"orfs.faa\"\n",
      "        path \"orfs.gbk\"\n",
      "\n",
      "    script:\n",
      "    \"\"\"\n",
      "    echo \"${_AlhL},contigs\" >>inputs.txt\n",
      "    echo \"orfs.faa,orfs_faa\" >>outputs.txt\n",
      "    echo \"orfs.gbk,orfs_gbk\" >>outputs.txt\n",
      "    echo \"/home/tony/workspace/tools/Metasmith/main/local_mock/transforms/simple_1/pprodigal.py\" >>transform.txt\n",
      "    bash /home/tony/workspace/tools/Metasmith/main/local_mock/entry.sh\n",
      "    \"\"\"\n",
      "}\n",
      "\n",
      "process diamond__5leR {\n",
      "    container \"docker://bschiffthaler/diamond:2.0.14\"\n",
      "    publishDir \"$params.output\", mode: \"copy\", pattern: \"annotations.csv\"\n",
      "\n",
      "    input:\n",
      "        path _4yRt\n",
      "        path _KEYf\n",
      "\n",
      "    output:\n",
      "        path \"annotations.csv\"\n",
      "\n",
      "    script:\n",
      "    \"\"\"\n",
      "    echo \"${_4yRt},diamond_protein_reference\" >>inputs.txt\n",
      "    echo \"${_KEYf},orfs_faa\" >>inputs.txt\n",
      "    echo \"annotations.csv,orf_annotations\" >>outputs.txt\n",
      "    echo \"/home/tony/workspace/tools/Metasmith/main/local_mock/transforms/simple_1/diamond.py\" >>transform.txt\n",
      "    bash /home/tony/workspace/tools/Metasmith/main/local_mock/entry.sh\n",
      "    \"\"\"\n",
      "}\n",
      "\n",
      "workflow {\n",
      "    _AlhL = Channel.fromPath(params.given_AlhL)\n",
      "    _4yRt = Channel.fromPath(params.given_4yRt)\n",
      "\n",
      "    (_KEYf, _wR9p) = pprodigal__VMBv(_AlhL)\n",
      "    _dh6J = diamond__5leR(_4yRt, _KEYf)\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "WS = Path(\"./cache/ws1/nextflow\")\n",
    "WS.mkdir(exist_ok=True)\n",
    "TAB = \" \"*4\n",
    "\n",
    "wf_path = WS/\"workflow.nf\"\n",
    "process_definitions = []\n",
    "workflow_definition = []\n",
    "target_endpoints = {e for x, e in plan.targets}\n",
    "for step in plan.steps:\n",
    "    name = f\"{step.transform.source.stem}__{step.key}\"\n",
    "    src = [f\"process {name}\"+\" {\"]\n",
    "\n",
    "    to_pubish = [x for x, e in step.produces if e in target_endpoints]\n",
    "    for x in to_pubish:\n",
    "        src.append(TAB+f'publishDir \"$params.output\", mode: \"copy\", pattern: \"{x.source}\"')\n",
    "    if len(to_pubish)>0:\n",
    "        src.append(\"\") # newline\n",
    "    \n",
    "    src += [\n",
    "        TAB+\"input:\",\n",
    "    ] + [\n",
    "        TAB+TAB+f'path _{e.key}' for x, e in step.uses\n",
    "    ] + [\n",
    "        \"\",\n",
    "        TAB+\"output:\",\n",
    "    ] + [\n",
    "        TAB+TAB+f'path \"{x.source}\"' for x, e in step.produces\n",
    "    ] + [\n",
    "        \"\",\n",
    "        TAB+'script:',\n",
    "        TAB+'\"\"\"',\n",
    "    ] + [\n",
    "        TAB+'echo \"${_'+e.key+'},'+f'{x.type.name}\" >>inputs.txt' for x, e in step.uses\n",
    "    ] + [\n",
    "        TAB+f'echo \"{x.source},{x.type.name}\" >>outputs.txt' for x, e in step.produces\n",
    "    ] + [\n",
    "        TAB+f'echo \"{step.transform.source}\" >>transform.txt',\n",
    "        TAB+f'bash {Path(\"./entry.sh\").resolve()}',\n",
    "        TAB+'\"\"\"',\n",
    "        \"}\"\n",
    "    ]\n",
    "\n",
    "    output_vars = [f\"_{e.key}\" for x, e in step.produces]\n",
    "    output_vars = ', '.join(output_vars)\n",
    "    if len(step.produces) > 1:\n",
    "        output_vars = f\"({output_vars})\"\n",
    "    input_vars = [f\"_{e.key}\" for x, e in step.uses]\n",
    "    input_vars = ', '.join(input_vars)\n",
    "    process_definitions.append(\"\\n\".join(src))\n",
    "    workflow_definition.append(TAB+f'{output_vars} = {name}({input_vars})')\n",
    "\n",
    "workflow_definition = [\n",
    "    \"workflow {\"\n",
    "    ] + [\n",
    "        TAB+f'_{e.key}'+' = Channel.fromPath(params.given_'+f'{e.key}'+')' for x, e in plan.given\n",
    "    ] + [\n",
    "        \"\",\n",
    "    ] + workflow_definition + [\n",
    "        \"}\",\n",
    "    ]\n",
    "\n",
    "wf_contents = [\n",
    "    \"\\n\\n\".join(process_definitions),\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\".join(workflow_definition),\n",
    "    \"\\n\",\n",
    "]\n",
    "wf_contents = ''.join(wf_contents)\n",
    "with open(wf_path, \"w\") as f:\n",
    "    f.write(wf_contents)\n",
    "\n",
    "print(wf_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mNextflow 24.10.4 is available - Please consider updating your version to it\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " N E X T F L O W   ~  version 24.10.2\n",
      "\n",
      "Launching `/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/nextflow/workflow.nf` [sick_booth] DSL2 - revision: 7bd0186e73\n",
      "\n",
      "Plus 2 more processes waiting for tasks…\n",
      "\n",
      "executor >  local (1)\n",
      "[42/66c413] pprod | 0 of 1\n",
      "Plus 1 more processes waiting for tasks…\n",
      "\n",
      "executor >  local (1)\n",
      "[42/66c413] pprod | 0 of 1\n",
      "Plus 1 more processes waiting for tasks…\n",
      "\n",
      "executor >  local (1)\n",
      "[42/66c413] pprod | 0 of 1\n",
      "Plus 1 more processes waiting for tasks…\n",
      "ERROR ~ Error executing process > 'pprodigal__VMBv (1)'\n",
      "\n",
      "Caused by:\n",
      "  Missing output file(s) `orfs.faa` expected by process `pprodigal__VMBv (1)`\n",
      "\n",
      "\n",
      "Command executed:\n",
      "\n",
      "  echo \"example.fna,contigs\" >>inputs.txt\n",
      "  echo \"orfs.faa,orfs_faa\" >>outputs.txt\n",
      "  echo \"orfs.gbk,orfs_gbk\" >>outputs.txt\n",
      "  echo \"/home/tony/workspace/tools/Metasmith/main/local_mock/transforms/simple_1/pprodigal.py\" >>transform.txt\n",
      "  bash /home/tony/workspace/tools/Metasmith/main/local_mock/entry.sh\n",
      "\n",
      "Command exit status:\n",
      "  0\n",
      "\n",
      "Command output:\n",
      "  api call to [stage_slurm]\n",
      "  > Bootstrap Transform\n",
      "  contigs\n",
      "\n",
      "Command error:\n",
      "  Traceback (most recent call last):\n",
      "    File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "    File \"<frozen runpy>\", line 88, in _run_code\n",
      "    File \"/app/metasmith/__main__.py\", line 4, in <module>\n",
      "      main()\n",
      "    File \"/app/metasmith/coms/cli.py\", line 85, in main\n",
      "      COMMANDS.get(# calls command function with args\n",
      "    File \"/app/metasmith/coms/cli.py\", line 60, in api\n",
      "      HandleRequest(args.endpoint, body)\n",
      "    File \"/app/metasmith/coms/api.py\", line 20, in HandleRequest\n",
      "      _ENDPOINTS[endpoint](api, body)\n",
      "    File \"/app/metasmith/coms/api.py\", line 10, in stage_slurm\n",
      "      BootstrapTransform()\n",
      "    File \"/app/metasmith/agents/bootstrap.py\", line 15, in BootstrapTransform\n",
      "      with open(p) as f:\n",
      "           ^^^^^^^\n",
      "  FileNotFoundError: [Errno 2] No such file or directory: 'example.fna'\n",
      "\n",
      "Work dir:\n",
      "  /home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/nextflow/work/42/66c4131b5fcd4cc1b89f4021c71136\n",
      "\n",
      "Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`\n",
      "\n",
      " -- Check '/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/nextflow/logs/log' file for details\n",
      "\n",
      "executor >  local (1)\n",
      "[42/66c413] pprod | 1 of 1, failed: 1 ✘\n",
      "Plus 1 more processes waiting for tasks…\n",
      "ERROR ~ Error executing process > 'pprodigal__VMBv (1)'\n",
      "\n",
      "Caused by:\n",
      "  Missing output file(s) `orfs.faa` expected by process `pprodigal__VMBv (1)`\n",
      "\n",
      "\n",
      "Command executed:\n",
      "\n",
      "  echo \"example.fna,contigs\" >>inputs.txt\n",
      "  echo \"orfs.faa,orfs_faa\" >>outputs.txt\n",
      "  echo \"orfs.gbk,orfs_gbk\" >>outputs.txt\n",
      "  echo \"/home/tony/workspace/tools/Metasmith/main/local_mock/transforms/simple_1/pprodigal.py\" >>transform.txt\n",
      "  bash /home/tony/workspace/tools/Metasmith/main/local_mock/entry.sh\n",
      "\n",
      "Command exit status:\n",
      "  0\n",
      "\n",
      "Command output:\n",
      "  api call to [stage_slurm]\n",
      "  > Bootstrap Transform\n",
      "  contigs\n",
      "\n",
      "Command error:\n",
      "  Traceback (most recent call last):\n",
      "    File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "    File \"<frozen runpy>\", line 88, in _run_code\n",
      "    File \"/app/metasmith/__main__.py\", line 4, in <module>\n",
      "      main()\n",
      "    File \"/app/metasmith/coms/cli.py\", line 85, in main\n",
      "      COMMANDS.get(# calls command function with args\n",
      "    File \"/app/metasmith/coms/cli.py\", line 60, in api\n",
      "      HandleRequest(args.endpoint, body)\n",
      "    File \"/app/metasmith/coms/api.py\", line 20, in HandleRequest\n",
      "      _ENDPOINTS[endpoint](api, body)\n",
      "    File \"/app/metasmith/coms/api.py\", line 10, in stage_slurm\n",
      "      BootstrapTransform()\n",
      "    File \"/app/metasmith/agents/bootstrap.py\", line 15, in BootstrapTransform\n",
      "      with open(p) as f:\n",
      "           ^^^^^^^\n",
      "  FileNotFoundError: [Errno 2] No such file or directory: 'example.fna'\n",
      "\n",
      "Work dir:\n",
      "  /home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/nextflow/work/42/66c4131b5fcd4cc1b89f4021c71136\n",
      "\n",
      "Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`\n",
      "\n",
      " -- Check '/home/tony/workspace/tools/Metasmith/main/local_mock/cache/ws1/nextflow/logs/log' file for details\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# nextflow -C ../config.nf -log ./.nextflow_logs/log \\\n",
    "#     run ../test.2.nf \\\n",
    "#     --given_OVtA given/2beaver_fosmid_seqs.fna given/contigs.fna \\\n",
    "#     --given_bAYL given/swissprot_fastal_ref \\\n",
    "#     --account asdf\n",
    "\n",
    "param_given = [f\"--given_{e.key} {x.source}\" for x, e in plan.given]\n",
    "param_given = ' '.join(param_given)\n",
    "os.system(f\"\"\"\\\n",
    "cd ./cache/ws1/nextflow\n",
    "nextflow -C ../../../config/nxf_local.nf \\\n",
    "    -log {(WS/\"logs\").resolve()}/log \\\n",
    "    run {wf_path.resolve()} \\\n",
    "    -work-dir {(WS/\"work\").resolve()} \\\n",
    "    {param_given}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DataInstance(source=PosixPath('annotations.csv'), type=DataType(name='orf_annotations', properties={'format': 'CSV', 'data': 'Protein features'}, library=DataTypeLibrary(path=PosixPath('/home/tony/workspace/tools/Metasmith/main/local_mock/prototypes/metagenomics.yml'), schema=0.3, ontology={'doi': 'https://doi.org/10.1093/bioinformatics/btt113', 'name': 'EDAM', 'version': 1.25, 'strict': False}, types={'contigs': DataType(name='contigs', properties={'format': 'FASTA', 'data': 'DNA sequence'}, library=...), 'orfs_gbk': DataType(name='orfs_gbk', properties={'format': 'GenBank', 'data': 'Protein features'}, library=...), 'orfs_faa': DataType(name='orfs_faa', properties={'format': 'FASTA', 'data': 'Amino acid sequence'}, library=...), 'diamond_protein_reference': DataType(name='diamond_protein_reference', properties={'format': 'Binary format', 'data': 'database reference', 'reference_type': 'diamond db'}, library=...), 'fastal_protein_reference': DataType(name='fastal_protein_reference', properties={'format': 'Binary format', 'data': 'database reference', 'reference_type': 'diamond db'}, library=...), 'orf_annotations': ...}))),\n",
       "  (format=CSV-data=Protein features:dh6J))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step.produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WorkflowPlan' object has no attribute 'produces'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduces\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WorkflowPlan' object has no attribute 'produces'"
     ]
    }
   ],
   "source": [
    "plan.produces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
